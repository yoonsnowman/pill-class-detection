{"cells":[{"cell_type":"code","source":["\"\"\" ê°œë°œí™˜ê²½ ì„¤ì • \"\"\"\n","def develop(environment='base'):\n","    n1, d1 = 'base',    'data/project1data'\n","    n2, d2 = 'train',   'data/project1data/raw/train_images'\n","    n3, d3 = 'test',    'data/project1data/raw/test_images'\n","    n4, d4 = 'font',    'data/project1data/raw/NanumGothic.ttf'\n","    n5, d5 = 'labels',  'data/project1data/raw/processed/labels'\n","    n6, d6 = 'classes', 'data/project1data/raw/processed/classes.txt'\n","    dirs = {n1:d1, n2:d2, n3:d3, n4:d4, n5:d5, n6:d6}\n","\n","    local_path = 'G:/ë‚´ ë“œë¼ì´ë¸Œ/dev/'\n","    cloud_path = '/content/drive/MyDrive/dev'\n","    env_path = f'{cloud_path}/environment/{environment}'\n","\n","    import os, sys\n","    if 'google' in sys.modules:\n","        from google.colab import drive; drive.mount('/content/drive')\n","        if env_path not in sys.path: sys.path.insert(0, env_path)\n","        os.environ['TORCH_HOME'] = f'{cloud_path}/model/pytorch_model'\n","        return {k: os.path.join(cloud_path, v) for k, v in dirs.items()}\n","    else: return {k: os.path.join(local_path, v) for k, v in dirs.items()}\n","for k, v in develop().items(): print(f\"{k:10}: {v}\")\n","DIR = develop() # !pip install --target=/content/drive/MyDrive/dev/environment/base ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAD5nCql1aQ3","executionInfo":{"status":"ok","timestamp":1748334389968,"user_tz":-540,"elapsed":3052,"user":{"displayName":"ìœ¤ìŠ¹í˜¸","userId":"12000380697036944794"}},"outputId":"05fcfd77-ce0a-4e09-a7db-b6cf0a28a5ff"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","base      : /content/drive/MyDrive/dev/data/project1data\n","train     : /content/drive/MyDrive/dev/data/project1data/raw/train_images\n","test      : /content/drive/MyDrive/dev/data/project1data/raw/test_images\n","font      : /content/drive/MyDrive/dev/data/project1data/raw/NanumGothic.ttf\n","labels    : /content/drive/MyDrive/dev/data/project1data/raw/processed/labels\n","classes   : /content/drive/MyDrive/dev/data/project1data/raw/processed/classes.txt\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1hYHFH2Bn5PL1rhayb9DzodGVwinIEKIp"},"executionInfo":{"elapsed":324076,"status":"ok","timestamp":1748334301706,"user":{"displayName":"ìœ¤ìŠ¹í˜¸","userId":"12000380697036944794"},"user_tz":-540},"id":"u8ETrkmQERpk","outputId":"88ed9717-b893-4634-aca0-b0efc577cd30"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["\n","\"\"\" ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ \"\"\"\n","!pip install torchinfo\n","# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import os, shutil\n","import random\n","import json\n","from collections import defaultdict, Counter\n","# ìˆ˜ì¹˜/ì‹œê°í™”\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","# PIL\n","from PIL import Image, ImageDraw, ImageFont\n","# PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch import amp\n","from torch.cuda.amp import GradScaler, autocast\n","from torchinfo import summary\n","# ë°ì´í„° ë¡œë”\n","from torch.utils.data import Dataset, DataLoader\n","# torchvision\n","from torchvision import datasets, transforms\n","from torchvision.transforms import v2\n","# ì§„í–‰ í‘œì‹œ\n","from tqdm import tqdm\n","# ë¨¸ì‹ ëŸ¬ë‹ í‰ê°€ ì§€í‘œ\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    confusion_matrix, classification_report,\n","    roc_auc_score, roc_curve\n",")\n","from sklearn.model_selection import train_test_split\n","# ë°ì´í„° ì¦ê°•\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","\n","\"\"\" ë°ì´í„° ì „ì²˜ë¦¬ \"\"\"\n","# Helper í´ë˜ìŠ¤\n","class PillAnnotationParser:\n","    def __init__(self, annotation_root, output_dir):\n","        self.annotation_root = annotation_root\n","        self.output_dir = output_dir\n","        self.image_data = []\n","        self.annotations = []\n","        self.categories = {}\n","        self.class_map = {}\n","\n","    def _find_json_files(self):\n","        json_paths = []\n","        for root, _, files in os.walk(self.annotation_root):\n","            for file in files:\n","                if file.endswith('.json'):\n","                    json_paths.append(os.path.join(root, file))\n","        print(f\"ğŸ” JSON íŒŒì¼ {len(json_paths)}ê°œ ë°œê²¬ë¨\")\n","        return json_paths\n","\n","    def load_annotations(self):\n","        print(\"ğŸ“‚ ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ ì¤‘...\")\n","        json_files = self._find_json_files()\n","\n","        for path in tqdm(json_files, desc=\"ğŸ“‘ JSON ì²˜ë¦¬ ì¤‘\"):\n","            try:\n","                with open(path, 'r', encoding='utf-8') as f:\n","                    data = json.load(f)\n","                    if 'images' in data and 'annotations' in data:\n","                        self.image_data.extend(data['images'])\n","                        self.annotations.extend(data['annotations'])\n","                        for cat in data.get('categories', []):\n","                            self.categories[cat['id']] = cat['name']\n","            except Exception as e:\n","                print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {path}\")\n","                print(f\"    {e}\")\n","        print(f\"âœ… ì´ë¯¸ì§€ {len(self.image_data)}ê°œ, ì–´ë…¸í…Œì´ì…˜ {len(self.annotations)}ê°œ ë¡œë“œ ì™„ë£Œ\")\n","\n","    def generate_class_map(self):\n","        print(\"ğŸ§  ì „ì²´ í´ë˜ìŠ¤ ë§µ ìƒì„± ì¤‘...\")\n","        class_ids = set(ann['category_id'] for ann in self.annotations)\n","        self.class_map = {cat_id: idx for idx, cat_id in enumerate(sorted(class_ids))}\n","        print(f\"âœ… ì´ {len(self.class_map)}ê°œ í´ë˜ìŠ¤ ë§¤í•‘ ì™„ë£Œ!\")\n","\n","\n","    def save_yolo_annotations(self):\n","        labels_dir = os.path.join(self.output_dir, 'labels')\n","        os.makedirs(labels_dir, exist_ok=True)\n","        print(\"ğŸš€ YOLO ë¼ë²¨ ì €ì¥ ì‹œì‘...\")\n","\n","        image_id_map = {img['id']: img for img in self.image_data}\n","        label_files = defaultdict(list)\n","        count = 0\n","\n","        for ann in self.annotations:\n","            cat_id = ann['category_id']\n","            if cat_id not in self.class_map:\n","                continue\n","\n","            img_info = image_id_map[ann['image_id']]\n","            w, h = img_info['width'], img_info['height']\n","            x, y, bw, bh = ann['bbox']\n","\n","            x_center = (x + bw / 2) / w\n","            y_center = (y + bh / 2) / h\n","            w_norm = bw / w\n","            h_norm = bh / h\n","            class_idx = self.class_map[cat_id]\n","\n","            label_line = f\"{class_idx} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\"\n","            label_files[img_info['file_name']].append(label_line)\n","            count += 1\n","\n","        for filename, lines in label_files.items():\n","            txt_name = os.path.splitext(filename)[0] + '.txt'\n","            with open(os.path.join(labels_dir, txt_name), 'w') as f:\n","                f.write('\\n'.join(lines))\n","\n","        print(f\"âœ… ì´ {count}ê°œ ì–´ë…¸í…Œì´ì…˜ ì €ì¥ ì™„ë£Œ! ({labels_dir})\")\n","\n","    def export_class_map(self):\n","        class_txt_path = os.path.join(self.output_dir, 'classes.txt')\n","        with open(class_txt_path, 'w') as f:\n","            sorted_items = sorted(self.class_map.items(), key=lambda x: x[1])\n","            for cat_id, new_id in sorted_items:\n","                name = self.categories.get(cat_id, 'unknown')\n","                f.write(f\"{new_id}: {name}\\n\")\n","        print(f\"ğŸ“ í´ë˜ìŠ¤ ë§µ ì €ì¥ ì™„ë£Œ: {class_txt_path}\")\n","\n","# # ğŸ ì‹¤í–‰ ì½”ë“œ\n","# if __name__ == \"__main__\":\n","#     parser = PillAnnotationParser(\n","#         annotation_root='/content/drive/MyDrive/dev/data/project1data/raw/train_annotations',\n","#         output_dir='/content/drive/MyDrive/dev/data/project1data/raw/processed'\n","#     )\n","\n","#     parser.load_annotations()\n","#     parser.generate_class_map()\n","#     parser.save_yolo_annotations()\n","#     parser.export_class_map()\n","\n","\n","\"\"\" BBOX ë§¤í•‘ í™•ì¸ ì‹œê°í™” \"\"\"\n","# ì‹œê°í™”\n","def load_class_names(path):\n","    class_names = []\n","    with open(path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            _, name = line.strip().split(': ')\n","            class_names.append(name)\n","    return class_names\n","\n","def draw_yolo_bbox_on_image(image_path, label_path, class_names, font_path):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    draw = ImageDraw.Draw(image)\n","    w, h = image.size\n","\n","    try:\n","        font = ImageFont.truetype(font_path, 30)\n","    except:\n","        font = ImageFont.load_default()\n","\n","    if not os.path.exists(label_path):\n","        return image  # ê·¸ëƒ¥ ì´ë¯¸ì§€ë§Œ ë°˜í™˜\n","\n","    with open(label_path, 'r') as f:\n","        lines = f.readlines()\n","\n","    for line in lines:\n","        parts = line.strip().split()\n","        cls = int(parts[0])\n","        x_c, y_c, bw, bh = map(float, parts[1:])\n","\n","        x1 = int((x_c - bw/2) * w)\n","        y1 = int((y_c - bh/2) * h)\n","        x2 = int((x_c + bw/2) * w)\n","        y2 = int((y_c + bh/2) * h)\n","\n","        draw.rectangle([x1, y1, x2, y2], outline=\"lime\", width=3)\n","\n","        label = class_names[cls] if class_names else f\"{cls}\"\n","        text_bbox = draw.textbbox((0, 0), label, font=font)\n","        text_width = text_bbox[2] - text_bbox[0]\n","        text_height = text_bbox[3] - text_bbox[1]\n","\n","        text_x = x1\n","        text_y = y1 - text_height - 6\n","        if text_y < 0:\n","            text_y = y1 + 4\n","\n","        draw.rectangle(\n","            [text_x, text_y, text_x + text_width + 6, text_y + text_height + 4],\n","            fill=\"black\"\n","        )\n","        draw.text((text_x + 3, text_y + 2), label, font=font, fill=\"lime\")\n","\n","    return image\n","\n","def show_yolo_images_grid(image_dir, label_dir, class_names, font_path, count=9):\n","    image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n","    random.shuffle(image_files)\n","\n","    images = []\n","    for img_file in image_files:\n","        img_path = os.path.join(image_dir, img_file)\n","        label_path = os.path.join(label_dir, img_file.replace('.png', '.txt'))\n","\n","        if os.path.exists(label_path):\n","            img = draw_yolo_bbox_on_image(img_path, label_path, class_names, font_path)\n","            images.append(img)\n","        if len(images) == count:\n","            break\n","\n","    fig, axes = plt.subplots(3, 3, figsize=(30, 30))\n","    for ax, img in zip(axes.flat, images):\n","        ax.imshow(img)\n","        ax.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","show_yolo_images_grid(DIR['train'], DIR['labels'], load_class_names(DIR['classes']), DIR['font'], count=9)\n","\n","\n","\n","\n","\"\"\" ë°ì´í„°ì…‹ ìŠ¤í”Œë¦¿ \"\"\"\n","# Dataset í´ë˜ìŠ¤\n","class PillDataset(Dataset):\n","    def __init__(self, image_dir, label_dir, file_list, transform=None):\n","        self.image_dir = image_dir\n","        self.label_dir = label_dir\n","        self.files = file_list\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self, idx):\n","        # 1) ì´ë¯¸ì§€, bboxÂ·label ë¡œë“œ\n","        name    = self.files[idx]\n","        img_np  = np.array(Image.open(os.path.join(self.image_dir, name)).convert(\"RGB\"))\n","        lbl_path= os.path.join(self.label_dir, name.replace('.png','.txt'))\n","        boxes, labels = [], []\n","        if os.path.exists(lbl_path):\n","            for line in open(lbl_path):\n","                cls, x_c, y_c, w, h = map(float, line.split())\n","                labels.append(int(cls)); boxes.append([x_c, y_c, w, h])\n","\n","        # 2) Albumentations transform í˜¸ì¶œ (image, bboxes, class_labels ëª¨ë‘ ë„˜ê²¨ì¤Œ)\n","        if self.transform:\n","            data = self.transform(image=img_np, bboxes=boxes, class_labels=labels)\n","            image  = data['image']\n","            boxes  = data['bboxes']\n","            labels = data['class_labels']\n","        else:\n","            image = ToTensorV2()(image=img_np)['image']  # fallback\n","\n","        # 3) tensorë¡œ ë³€í™˜\n","        target = {\n","            \"boxes\":  torch.tensor(boxes,  dtype=torch.float32),\n","            \"labels\": torch.tensor(labels,dtype=torch.int64)\n","        }\n","        return image, target\n","\n","# ë°ì´í„° ì¦ê°•\n","train_transform = A.Compose([\n","    A.Resize(640, 640),\n","    A.Affine(translate_percent=(0.1, 0.1), scale=(0.9, 1.1), rotate=15, shear=5, p=0.5),\n","    A.HorizontalFlip(p=0.5),\n","    A.RandomBrightnessContrast(p=0.5),\n","    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","    ToTensorV2()\n","], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n","\n","test_transform = A.Compose([\n","    A.Resize(640, 640),\n","    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","    ToTensorV2()\n","], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n","\n","# ë°ì´í„° ìŠ¤í”Œë¦¿\n","all_imgs = [f for f in os.listdir(DIR['train']) if f.endswith('.png')]\n","train_files, val_files = train_test_split(all_imgs, test_size=0.2, random_state=42)\n","test_files = [f for f in os.listdir(DIR['test']) if f.endswith('.png')]\n","\n","train_dataset = PillDataset(image_dir=DIR['train'], label_dir=DIR['labels'], file_list=train_files, transform=train_transform)\n","val_dataset   = PillDataset(image_dir=DIR['train'], label_dir=DIR['labels'], file_list=val_files,   transform=test_transform)\n","test_dataset  = PillDataset(image_dir=DIR['test'],  label_dir=DIR['labels'], file_list=test_files, transform=test_transform)\n","\n","train_loader  = DataLoader(train_dataset, batch_size=16, shuffle=True,  collate_fn=lambda batch: tuple(zip(*batch)))\n","val_loader    = DataLoader(val_dataset,   batch_size=16, shuffle=False, collate_fn=lambda batch: tuple(zip(*batch)))\n","test_loader   = DataLoader(test_dataset,  batch_size=16, shuffle=False, collate_fn=lambda batch: tuple(zip(*batch)))\n","\n","imgs, targets = next(iter(train_loader))\n","imgs = torch.stack(imgs)         # list/tuple â†’ (B, C, H, W) tensor\n","print(imgs.shape)                # e.g. torch.Size([16, 3, 640, 640])\n","print([t['boxes'].shape for t in targets])\n","\n","\n","\n","\"\"\" ëª¨ë¸ ì¸í’‹ ë°ì´í„° ì‹œê°í™” \"\"\"\n","# ì‹œê°í™”\n","def show_augmented_bbox_images(dataset, count=9):\n","    indices = random.sample(range(len(dataset)), count)\n","    fig, axes = plt.subplots(3, 3, figsize=(30, 30))\n","    for ax, idx in zip(axes.flat, indices):\n","        img_tensor, target = dataset[idx]\n","        img = img_tensor.permute(1, 2, 0).cpu().numpy()\n","        img = img * 0.5 + 0.5\n","        h, w, _ = img.shape\n","        ax.imshow(img)\n","        for x_c, y_c, bw, bh in target['boxes'].cpu().numpy():\n","            x1 = (x_c - bw/2) * w\n","            y1 = (y_c - bh/2) * h\n","            rect = patches.Rectangle((x1, y1), bw * w, bh * h,\n","                                     linewidth=2, edgecolor='lime', facecolor='none')\n","            ax.add_patch(rect)\n","        ax.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","show_augmented_bbox_images(train_dataset)\n"]},{"cell_type":"code","source":["\n","\n","def create_yolo_dataset_split(train_files, val_files, test_files):\n","    base = DIR['base']\n","    src_img_train = DIR['train']\n","    src_img_test  = DIR['test']\n","    src_labels    = DIR['labels']\n","\n","    target_struct = {\n","        'train': {'files': train_files, 'img_src': src_img_train},\n","        'val':   {'files': val_files,   'img_src': src_img_train},\n","        'test':  {'files': test_files,  'img_src': src_img_test},\n","    }\n","\n","    for split, cfg in target_struct.items():\n","        img_dst = os.path.join(base, split, 'images')\n","        lbl_dst = os.path.join(base, split, 'labels')\n","        os.makedirs(img_dst, exist_ok=True)\n","        os.makedirs(lbl_dst, exist_ok=True)\n","\n","        img_copied = 0\n","        img_skipped = 0\n","        lbl_copied = 0\n","        lbl_skipped = 0\n","\n","        for fname in cfg['files']:\n","            # ì´ë¯¸ì§€\n","            src_img_path = os.path.join(cfg['img_src'], fname)\n","            dst_img_path = os.path.join(img_dst, fname)\n","            if os.path.exists(dst_img_path):\n","                img_skipped += 1\n","            elif os.path.exists(src_img_path):\n","                shutil.copy(src_img_path, dst_img_path)\n","                img_copied += 1\n","\n","            # ë¼ë²¨\n","            lbl_name = fname.replace('.png', '.txt')\n","            src_lbl_path = os.path.join(src_labels, lbl_name)\n","            dst_lbl_path = os.path.join(lbl_dst, lbl_name)\n","            if os.path.exists(dst_lbl_path):\n","                lbl_skipped += 1\n","            elif os.path.exists(src_lbl_path):\n","                shutil.copy(src_lbl_path, dst_lbl_path)\n","                lbl_copied += 1\n","\n","        print(f'ğŸ“ [{split.upper()}] images: ë³µì‚¬ ì™„ë£Œ {img_copied}ê°œ / ì´ë¯¸ ì¡´ì¬ {img_skipped}ê°œ')\n","        print(f'ğŸ“ [{split.upper()}] labels: ë³µì‚¬ ì™„ë£Œ {lbl_copied}ê°œ / ì´ë¯¸ ì¡´ì¬ {lbl_skipped}ê°œ\\n')\n","\n","create_yolo_dataset_split(train_files, val_files, test_files)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uY6YFPtc1WVK","executionInfo":{"status":"ok","timestamp":1748337194198,"user_tz":-540,"elapsed":1739,"user":{"displayName":"ìœ¤ìŠ¹í˜¸","userId":"12000380697036944794"}},"outputId":"877920b4-e7e8-40ef-9649-db7776d0920b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“ [TRAIN] images: ë³µì‚¬ ì™„ë£Œ 0ê°œ / ì´ë¯¸ ì¡´ì¬ 1191ê°œ\n","ğŸ“ [TRAIN] labels: ë³µì‚¬ ì™„ë£Œ 0ê°œ / ì´ë¯¸ ì¡´ì¬ 1191ê°œ\n","\n","ğŸ“ [VAL] images: ë³µì‚¬ ì™„ë£Œ 0ê°œ / ì´ë¯¸ ì¡´ì¬ 298ê°œ\n","ğŸ“ [VAL] labels: ë³µì‚¬ ì™„ë£Œ 0ê°œ / ì´ë¯¸ ì¡´ì¬ 298ê°œ\n","\n","ğŸ“ [TEST] images: ë³µì‚¬ ì™„ë£Œ 0ê°œ / ì´ë¯¸ ì¡´ì¬ 843ê°œ\n","ğŸ“ [TEST] labels: ë³µì‚¬ ì™„ë£Œ 0ê°œ / ì´ë¯¸ ì¡´ì¬ 0ê°œ\n","\n"]}]},{"cell_type":"code","source":["!pip install --target=\"{env_path}\" ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"Bq1WecxTBrUI","executionInfo":{"status":"error","timestamp":1748337430550,"user_tz":-540,"elapsed":214,"user":{"displayName":"ìœ¤ìŠ¹í˜¸","userId":"12000380697036944794"}},"outputId":"bdcff0a6-7533-4088-c135-05287fb78d22"},"execution_count":17,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'ultralytics'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0bf2fd45f7d1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.12"}},"nbformat":4,"nbformat_minor":0}