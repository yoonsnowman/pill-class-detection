{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kangdongwoo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n",
      "Output will be saved to: ../models/detr_output\n",
      "DETR Image Processor loaded: facebook/detr-resnet-50\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1.1. 설정 (Configuration) ---\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # 훈련 데이터셋 경로\n",
    "        self.train_image_dir = '../data/detr/train_images'\n",
    "        self.train_annotation_file = '../data/detr/annotations/train.json'\n",
    "        # 테스트 데이터셋 경로\n",
    "        self.test_image_dir = '../data/detr/test_images'\n",
    "\n",
    "        # 사용할 DETR 모델 이름\n",
    "        self.model_name = \"facebook/detr-resnet-50\" # 사전 훈련된 DETR ResNet-50 모델\n",
    "\n",
    "        # 결과물 (모델 가중치, 예측 이미지) 저장 경로\n",
    "        self.output_dir = '../models'\n",
    "\n",
    "        # 학습 관련 파라미터\n",
    "        self.epochs = 1  # 실제 학습 시에는 더 많은 Epoch가 필요할 수 있습니다.\n",
    "        self.batch_size = 1\n",
    "        self.learning_rate = 1e-4\n",
    "\n",
    "        # 사용 디바이스 (GPU 사용 가능 시 'cuda', 아니면 'cpu')\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # 예측 시각화 관련 파라미터\n",
    "        self.viz_num_images = 5 # 테스트 데이터셋에서 시각화할 이미지 수\n",
    "        self.detection_threshold = 0.9 # 예측 신뢰도 임계값 (이 값 이상인 예측만 시각화)\n",
    "\n",
    "# Config 인스턴스 생성\n",
    "config = Config()\n",
    "print(f\"Running on device: {config.device}\")\n",
    "print(f\"Output will be saved to: {config.output_dir}\")\n",
    "\n",
    "# --- 1.2. 모델 이미지 프로세서 로드 ---\n",
    "# 이 프로세서는 DETR 모델 입력에 맞게 이미지를 전처리합니다.\n",
    "image_processor = DetrImageProcessor.from_pretrained(config.model_name)\n",
    "print(f\"DETR Image Processor loaded: {config.model_name}\")\n",
    "\n",
    "# 이 코드를 실행하기 전에 `train_image_dir`, `train_annotation_file`, `test_image_dir`의 경로를\n",
    "# 실제 파일이 있는 곳으로 **반드시 수정**해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2321cf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Train dataset size: 1489\n",
      "Test dataset size: 843\n",
      "Number of categories: 73\n",
      "Categories: {0: '보령부스파정 5mg', 1: '동아가바펜틴정 800mg', 2: '낙소졸정 500/20mg', 3: '신바로정', 4: '가바토파정 100mg', 5: '란스톤엘에프디티정 30mg', 6: '펠루비정(펠루비프로펜)', 7: '울트라셋이알서방정', 8: '비모보정 500/20mg', 9: '레일라정', 10: '스토가정 10mg', 11: '라비에트정 20mg', 12: '놀텍정 10mg', 13: '에스원엠프정 20mg', 14: '케이캡정 50mg', 15: '뮤테란캡슐 100mg', 16: '알드린정', 17: '타이레놀정500mg', 18: '삐콤씨에프정 618.6mg/병', 19: '다보타민큐정 10mg/병', 20: '트루비타정 60mg/병', 21: '메가파워정 90mg/병', 22: '비타비백정 100mg/병', 23: '타이레놀이알서방정(아세트아미노펜)(수출용)', 24: '리렉스펜정 300mg/PTP', 25: '써스펜8시간이알서방정 650mg', 26: '맥시부펜이알정 300mg', 27: '삼남건조수산화알루미늄겔정', 28: '큐시드정 31.5mg/PTP', 29: '일양하이트린정 2mg', 30: '뉴로메드정(옥시라세탐)', 31: '리피토정 20mg', 32: '크레스토정 20mg', 33: '오마코연질캡슐(오메가-3-산에틸에스테르90)', 34: '플라빅스정 75mg', 35: '아토르바정 10mg', 36: '리피로우정 20mg', 37: '리바로정 4mg', 38: '아토젯정 10/40mg', 39: '로수젯정10/5밀리그램', 40: '로수바미브정 10/20mg', 41: '에빅사정(메만틴염산염)(비매품)', 42: '리리카캡슐 150mg', 43: '종근당글리아티린연질캡슐(콜린알포세레이트)\\xa0', 44: '콜리네이트연질캡슐 400mg', 45: '마도파정', 46: '아질렉트정(라사길린메실산염)', 47: '글리아타민연질캡슐', 48: '글리틴정(콜린알포세레이트)', 49: '카발린캡슐 25mg', 50: '기넥신에프정(은행엽엑스)(수출용)', 51: '노바스크정 5mg', 52: '자누비아정 50mg', 53: '트라젠타정(리나글립틴)', 54: '트라젠타듀오정 2.5/850mg', 55: '자누메트엑스알서방정 100/1000mg', 56: '제미메트서방정 50/1000mg', 57: '엑스포지정 5/160mg', 58: '자누메트정 50/850mg', 59: '아모잘탄정 5/100mg', 60: '세비카정 10/40mg', 61: '트윈스타정 40/5mg', 62: '카나브정 60mg', 63: '무코스타정(레바미피드)(비매품)', 64: '에어탈정(아세클로페낙)', 65: '쎄로켈정 100mg', 66: '아빌리파이정 10mg', 67: '자이프렉사정 2.5mg', 68: '쿠에타핀정 25mg', 69: '졸로푸트정 100mg', 70: '렉사프로정 15mg', 71: '브린텔릭스정 20mg', 72: '조인스정 200mg'}\n"
     ]
    }
   ],
   "source": [
    "# --- 2.1. 훈련 데이터셋 클래스 (COCO Detection Dataset) ---\n",
    "class CocoDetection(Dataset):\n",
    "    def __init__(self, img_folder, ann_file, image_processor):\n",
    "        self.img_folder = img_folder\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.img_ids = list(self.coco.imgs.keys())\n",
    "        self.image_processor = image_processor\n",
    "\n",
    "        self.categories = self.coco.loadCats(self.coco.getCatIds())\n",
    "        self.id_to_label = {c['id']: i for i, c in enumerate(self.categories)}\n",
    "        self.label_to_id = {i: c['id'] for i, c in enumerate(self.categories)}\n",
    "        self.label_to_name = {i: c['name'] for i, c in enumerate(self.categories)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0] # 이미지 정보 로드\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids) # 해당 이미지의 모든 원본 어노테이션 로드\n",
    "        path = img_info['file_name']\n",
    "\n",
    "        img = Image.open(os.path.join(self.img_folder, path)).convert('RGB')\n",
    "\n",
    "        # === 핵심 변경 부분 ===\n",
    "        # image_processor의 annotations 인자에 원본 COCO 포맷의 어노테이션 딕셔너리를 전달합니다.\n",
    "        # 이 딕셔너리는 'image_id'와 'annotations' (원본 어노테이션 리스트) 키를 포함해야 합니다.\n",
    "        coco_target = {\n",
    "            'image_id': img_id,\n",
    "            'annotations': anns # PyCOCOTools에서 로드한 원본 어노테이션 리스트 그대로 전달\n",
    "        }\n",
    "\n",
    "        # 이미지 전처리 및 어노테이션 변환을 image_processor에 맡깁니다.\n",
    "        # images 인자에는 단일 이미지 객체를, annotations 인자에는 위에서 정의한 coco_target을 리스트로 감싸서 전달\n",
    "        # 왜 리스트로 감싸는가? image_processor가 배치 처리(list of images)를 기본으로 하기 때문입니다.\n",
    "        # 단일 이미지를 전달할 때는 [image_obj] 로, 해당 이미지의 어노테이션을 [coco_target_dict] 로 전달합니다.\n",
    "        encoded_inputs = self.image_processor(images=[img], annotations=[coco_target], return_tensors=\"pt\")\n",
    "\n",
    "        # encoded_inputs는 'pixel_values'와 'labels' (boxes, class_labels)를 포함하는 딕셔너리\n",
    "        # 'pixel_values'는 배치 차원 (1)을 가지므로 제거하고, 'labels'는 [ {'boxes': ..., 'class_labels': ...} ] 형태이므로 첫 번째 요소를 사용\n",
    "        return {\n",
    "            'pixel_values': encoded_inputs['pixel_values'].squeeze(0), # 배치 차원 제거\n",
    "            'labels': encoded_inputs['labels'][0] # 리스트에서 유일한 어노테이션 딕셔너리 추출\n",
    "        }\n",
    "\n",
    "# 나머지 코드는 이전 답변과 동일하게 유지됩니다.\n",
    "# detr_collate_fn_train 및 test_dataloader, train_dataloader 생성 부분은 변경 없습니다.\n",
    "# --- 2.2. 테스트 데이터셋 클래스 (어노테이션 없음) ---\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, img_folder, image_processor, category_map):\n",
    "        self.img_folder = img_folder\n",
    "        self.image_processor = image_processor\n",
    "        self.image_files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        self.image_paths = [os.path.join(img_folder, f) for f in self.image_files]\n",
    "        self.label_to_name = category_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        encoded_inputs = self.image_processor(images=img, return_tensors=\"pt\")\n",
    "        return {\n",
    "            'pixel_values': encoded_inputs['pixel_values'].squeeze(0),\n",
    "            'original_image': img,\n",
    "            'image_filename': os.path.basename(img_path)\n",
    "        }\n",
    "\n",
    "# --- 2.3. 데이터 로더 Collate 함수 ---\n",
    "def detr_collate_fn_train(batch):\n",
    "    pixel_values = [item['pixel_values'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "    return {\n",
    "        'pixel_values': torch.stack(pixel_values),\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "def detr_collate_fn_test(batch):\n",
    "    pixel_values = [item['pixel_values'] for item in batch]\n",
    "    original_images = [item['original_image'] for item in batch]\n",
    "    image_filenames = [item['image_filename'] for item in batch]\n",
    "    return {\n",
    "        'pixel_values': torch.stack(pixel_values),\n",
    "        'original_images': original_images,\n",
    "        'image_filenames': image_filenames\n",
    "    }\n",
    "\n",
    "# --- 2.4. 데이터셋 및 데이터 로더 인스턴스 생성 ---\n",
    "train_dataset = CocoDetection(\n",
    "    img_folder=config.train_image_dir,\n",
    "    ann_file=config.train_annotation_file,\n",
    "    image_processor=image_processor\n",
    ")\n",
    "\n",
    "test_dataset = TestImageDataset(\n",
    "    img_folder=config.test_image_dir,\n",
    "    image_processor=image_processor,\n",
    "    category_map=train_dataset.label_to_name\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=detr_collate_fn_train)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=detr_collate_fn_test)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Number of categories: {len(train_dataset.categories)}\")\n",
    "print(f\"Categories: {train_dataset.label_to_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5830ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
      "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([74]) in the model instantiated\n",
      "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([74, 256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETR model loaded with 73 labels.\n",
      "Starting training on cpu for 1 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  49%|████▉     | 736/1489 [1:00:56<1:13:27,  5.85s/it]"
     ]
    }
   ],
   "source": [
    "# --- 3.1. DETR 모델 로드 및 최적화기 설정 ---\n",
    "model = DetrForObjectDetection.from_pretrained(\n",
    "    config.model_name,\n",
    "    num_labels=len(train_dataset.categories),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.to(config.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "print(f\"DETR model loaded with {len(train_dataset.categories)} labels.\")\n",
    "\n",
    "# --- 3.2. 모델 학습 루프 ---\n",
    "print(f\"Starting training on {config.device} for {config.epochs} epochs...\")\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{config.epochs}\")):\n",
    "        pixel_values = batch['pixel_values'].to(config.device)\n",
    "        labels = [{k: v.to(config.device) for k, v in t.items()} for t in batch['labels']]\n",
    "\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model_save_path = os.path.join(config.output_dir, f\"detr_model_epoch_{epoch+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# --- 3.3. 테스트 데이터셋 예측 및 시각화 ---\n",
    "model.eval()\n",
    "print(\"Starting prediction and visualization on test dataset (no ground truth)...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    num_visualized = 0\n",
    "    for batch_idx, batch in enumerate(tqdm(test_dataloader, desc=\"Predicting on test data\")):\n",
    "        if num_visualized >= config.viz_num_images:\n",
    "            break\n",
    "\n",
    "        pixel_values = batch['pixel_values'].to(config.device)\n",
    "        original_images = batch['original_images']\n",
    "        image_filenames = batch['image_filenames']\n",
    "\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "        logits = outputs.logits  # [batch_size, num_queries, num_classes]\n",
    "        pred_boxes = outputs.pred_boxes  # [batch_size, num_queries, 4]\n",
    "\n",
    "        for i in range(pixel_values.shape[0]):\n",
    "            if num_visualized >= config.viz_num_images:\n",
    "                break\n",
    "\n",
    "            original_img = original_images[i]\n",
    "            img_width, img_height = original_img.size\n",
    "            img_filename = image_filenames[i]\n",
    "\n",
    "            probas_i = logits[i].softmax(-1)  # [num_queries, num_classes]\n",
    "            bboxes_i = pred_boxes[i]  # [num_queries, 4]\n",
    "\n",
    "            # 예측 필터링: 배경 제외 + 임계값 이상\n",
    "            scores = probas_i.max(-1).values\n",
    "            labels = probas_i.argmax(-1)\n",
    "            keep = (scores > config.detection_threshold) & (labels != len(train_dataset.categories) - 1)\n",
    "\n",
    "            if keep.sum() == 0:\n",
    "                print(f\"[{img_filename}] No predictions passed threshold.\")\n",
    "                continue\n",
    "\n",
    "            filtered_boxes = bboxes_i[keep]\n",
    "            filtered_probas = probas_i[keep]\n",
    "\n",
    "            # 좌표 복원 (cxcywh → xywh)\n",
    "            filtered_boxes = filtered_boxes * torch.tensor(\n",
    "                [img_width, img_height, img_width, img_height],\n",
    "                device=filtered_boxes.device\n",
    "            )\n",
    "            boxes_xywh = torch.stack([\n",
    "                filtered_boxes[:, 0] - filtered_boxes[:, 2] / 2,  # x_min\n",
    "                filtered_boxes[:, 1] - filtered_boxes[:, 3] / 2,  # y_min\n",
    "                filtered_boxes[:, 2],  # width\n",
    "                filtered_boxes[:, 3]   # height\n",
    "            ], dim=1).cpu().numpy()\n",
    "\n",
    "            pred_labels = filtered_probas.argmax(-1).cpu().numpy()\n",
    "\n",
    "            fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "            ax.imshow(original_img)\n",
    "            ax.set_title(f\"Predicted Objects for {img_filename}\", fontsize=12)\n",
    "            ax.axis('off')\n",
    "\n",
    "            for box, label_idx in zip(boxes_xywh, pred_labels):\n",
    "                x_min, y_min, width, height = box\n",
    "                if width > 0 and height > 0:\n",
    "                    rect = patches.Rectangle(\n",
    "                        (x_min, y_min), width, height,\n",
    "                        linewidth=2, edgecolor='r', facecolor='none'\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "                    class_name = train_dataset.label_to_name.get(train_dataset.label_to_id[label_idx], 'Unknown')\n",
    "                    ax.text(x_min, y_min - 5, class_name, color='r', fontsize=10,\n",
    "                            bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "            viz_save_path = os.path.join(config.output_dir, f\"prediction_{os.path.splitext(img_filename)[0]}.png\")\n",
    "            plt.savefig(viz_save_path, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close(fig)\n",
    "\n",
    "            num_visualized += 1\n",
    "\n",
    "print(\"Prediction and visualization finished. Results saved to output directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06d385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([74])\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
